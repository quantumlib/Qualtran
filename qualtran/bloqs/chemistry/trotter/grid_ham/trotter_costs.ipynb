{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trotter Costs\n",
    "<p style=\"text-align: center;\"><a href=\"mailto:fmalone@google.com\">Fionn Malone</a></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We want to estimate the cost of implementing time evolution of a wavefunction:\n",
    "\n",
    "$$\n",
    "|\\psi(t)\\rangle = e^{-i H t}|\\psi(0)\\rangle\n",
    "$$\n",
    "\n",
    "fault tolerantly using qualtran. In practice applying the unitary directly is challenging as the Hamiltonian is made up of non-commuting terms. Note that if we write \n",
    "$$\n",
    "H = H_1 + H_2,\n",
    "$$\n",
    "we can always write\n",
    "$$\n",
    "e^{-i H t} = \\lim_{n\\rightarrow\\infty} \\left(e^{-iH_1 t/m} e^{-iH_2 t/m}\\right)^{m}.\n",
    "$$\n",
    "With this identity we can use Suzuki-Trotter methods to approximate the exact dynamics through product formulae. For example, the simplest Trotter approximation allows us to approximate the unitary as\n",
    "$$\n",
    "e^{-i H t} = \\prod_m^{N_t} e^{-iH_1 \\delta t} e^{-iH_2 \\delta t} + \\mathcal{O}(\\delta t^2)\n",
    "$$\n",
    "where we have $\\delta_t = t / N_t$ and the errors are proportional to commutators of the terms in the Hamiltonian. More sophisticated Trotter breakups lead to better accuracy, at the cost of more complicated product formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Quantized Grid Based Hamiltonian\n",
    "\n",
    "Ultimately we are interested in understanding the dynamics of real chemical systems. This requires us to study the ab-initio chemistry Hamiltonian which is given as (in atomic units)\n",
    "\n",
    "\\begin{align}\n",
    "H &= -\\frac{1}{2} \\sum_i \\nabla_i^2 -\\sum_{i}\\sum_{J} \\frac{\\zeta_J}{|R_J-r_i|} + \\sum_{i < j} \\frac{1}{|r_i-r_j|}  + \\mathrm{constant} \\\\\n",
    "  &= T + U + V.\n",
    "\\end{align}\n",
    "\n",
    "There are many different ways to represent the Hamiltonian, but here we will adopt a real space grid approach.\n",
    "That is, we imagine a collection of electrons in a cubic box of length $L$. We discretize real space with a certain resolution given by $\\Delta = L/(N-1)$ where $N$ is the number of grid points.  \n",
    "With this definition of the grid, then each of our $\\eta$ electrons can live at discrete real space points $r = (x, y, z)$ where $x = n_x \\Delta$, and $n_x \\in [-(N-1)/2, (N-1)/2]$. In fact, it is often more convenient in quantum algorithms to consider the unscaled grid points $\\bar{x} = x / \\Delta$, and work with tuples of integers directly. The scaling factors can be accounted for at a later time. \n",
    "\n",
    "To get a better handle on some of these things consider 1D case, and say we chose our grid to have 30 points in each of the positive and negative $x$ directions.\n",
    "Then $N = 2\\times 30 + 1 = 61$. If $L = 15 a_0 $ then $\\Delta = 15 / (21-1) \\approx 0.25 a_0$, where $a_0$ is the Bohr radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ng = 30\n",
    "x_int = np.linspace(-ng, ng, 2*ng+1, dtype=int)\n",
    "L = 15.0\n",
    "delta = L / (len(x_int) - 1)\n",
    "print(\"delta = \", delta)\n",
    "x_scl = delta * x_int\n",
    "assert (x_scl[-1] - x_scl[0]) - L < 1e-12\n",
    "\n",
    "print(f\"unscaled grid points = {x_int}\")\n",
    "print(f\"scaled grid points   = {x_scl}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our grid we can now visualize the coulomb potential sampled at these grid points: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "ij_pairs = np.triu_indices(len(x_int), k=1)\n",
    "rij = np.unique(np.sqrt((x_scl[ij_pairs[0]] - x_scl[ij_pairs[1]])**(2)))\n",
    "Vij = 1.0 / rij\n",
    "plt.plot(rij, Vij, marker='o', lw=0, label=\"grid\")\n",
    "xmin = np.min(rij)\n",
    "xmax = np.max(rij)\n",
    "rij_dense = np.linspace(xmin, xmax, 100)\n",
    "plt.plot(rij_dense, 1/rij_dense, lw=1, ls=\":\", label=\"1/r_{ij}\")\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$V(x) = 1/x$\")\n",
    "plt.title(\"Coulomb potential on a grid.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's look at the potential on our integer grid. The maximum distance should be 60 as our grid ranges from -30 to 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rij_int = np.unique(np.array(np.sqrt((x_int[ij_pairs[0]] - x_int[ij_pairs[1]])**(2)), dtype=int))\n",
    "Vij_int = 1.0 / rij_int\n",
    "plt.plot(rij_int, Vij_int, marker='o', lw=0, label=\"grid\")\n",
    "xmin = np.min(rij_int)\n",
    "xmax = np.max(rij_int)\n",
    "print(f\"xmin = {int(xmin)}, xmax = {int(xmax)}\")\n",
    "rij_dense = np.linspace(xmin, xmax, 100)\n",
    "plt.plot(rij_dense, 1/rij_dense, lw=1, ls=\":\", label=\"1/r_{ij}\")\n",
    "plt.xlabel(r\"$\\bar{x}$\")\n",
    "plt.ylabel(r\"$V(\\bar{x}) = 1/\\bar{x}$\")\n",
    "assert np.allclose(Vij_int/delta, Vij) \n",
    "assert np.allclose(rij_int*delta, rij) \n",
    "plt.title(\"Coulomb potential on a.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we have a handle on a grid Hamiltonian let's move onto how to simulate it on a quantum computer. \n",
    "\n",
    "Note in the above we assumed that $x>0$ which is not guaranteed. In practice we should this value of the potential to be a very large number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## Quantum Algorithm\n",
    "Our goal is to perform time evolution for our first quantized grid based Hamiltonian described above. \n",
    "\n",
    "Note that the Coulomb terms are diagonal in the position basis while the kinetic term is diagonal in the momentum basis. Thus we can employ a QFT to switch between these bases: \n",
    "$$\n",
    "|\\psi(t)\\rangle \\approx \\mathrm{QFT} e^{-i\\delta t T} \\mathrm{QFT}^{\\dagger} e^{-i\\delta t U}  e^{-i \\delta t V} |\\psi(0)\\rangle\n",
    "$$\n",
    "so that all the terms can be implemented via a gate which implements something of the form $e^{-i \\delta t \\phi_\\alpha }$ via phasing gates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can represent our $\\eta$-electron wavefunction as \n",
    "$$\n",
    "|\\psi\\rangle = \\sum_{r_1\\cdots r_\\eta} c(r_1, \\cdots, r_\\eta) |r_1\\cdots r_\\eta\\rangle\n",
    "$$\n",
    "\n",
    "and recall that each $r$ lives on a grid of size $N = (2 N_g + 1)^3$ if $N_g$ is the number of grid points in each spatial dimension. Thus we will need $\\eta$ registers of size $n = 3 \\lceil \\log N^{1/3}\\rceil + 1$ to describe our system.\n",
    "\n",
    "We will use the approach of Jones et al., which provides the following algorithm for implementing a single Trotter step (for the electron-electron interaction $V$, but the other terms are similar)\n",
    "\n",
    "\\begin{align}\n",
    "&\\sum_{r_1\\cdots r_\\eta} c(r_1, \\cdots, r_\\eta) |r_1\\cdots r_\\eta\\rangle \\\\\n",
    " \\rightarrow  &\\sum_{r_1\\cdots r_\\eta} c(r_1, \\cdots, r_\\eta) |r_1\\cdots r_\\eta\\rangle \n",
    "     |V(r_1\\cdots r_\\eta)\\rangle\n",
    "     \\hspace{10.4em} \\text{Compute pairwise potential in ancilla registers} \\\\\n",
    " \\rightarrow  &\\sum_{r_1\\cdots r_\\eta} e^{-i \\delta t V(r_1\\cdots r_\\eta)}\n",
    "     c(r_1, \\cdots, r_\\eta) |r_1\\cdots r_\\eta\\rangle|V(r_1\\cdots r_\\eta)\\rangle\n",
    "     \\hspace{5.5em} \\text{Phase the state with computed potential} \\\\ \n",
    " \\rightarrow &\\sum_{r_1\\cdots r_\\eta} e^{-i \\delta t V(r_1\\cdots r_\\eta)}\n",
    "     c(r_1, \\cdots, r_\\eta) |r_1\\cdots r_\\eta\\rangle|0\\cdots0\\rangle\n",
    "     \\hspace{7.8em} \\text{Uncompute potential in ancilla register} \\\\ \n",
    "\\end{align}\n",
    "in the above the ancilla register storing the value of the potential is of size $> 2n + 2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To compute the potential we need to evaluate $\\frac{1}{r_{ij}} \\equiv \\frac{1}{|r_i - r_j|}$ which can be done in two steps:\n",
    "\n",
    "1. compute $|r_{ij}^2\\rangle = |(x_i - x_j)^2 + (y_i-y_j)^2 + (z_i - z_j)^2\\rangle$ into a register of size $2 n + 2$.\n",
    "2. compute the inverse square root of the number in this register ($r_{ij}^2$).\n",
    "\n",
    "\n",
    "The most challenging and expensive part of this step is computing the inverse square root, which can classically be approximated using the Newton-Raphson method.\n",
    "To do so consider solving $x^{-2} = r_{ij}^2$ which has solution $x^* = \\frac{1}{r_{ij}}$. Our Newton-Raphson iteration is then: \n",
    "\n",
    "\\begin{align}\n",
    "a_{n+1} &= a_{n} - \\frac{a_n^3(1-r_{ij}^2 a_n^2)}{-2 a_n^2} \\\\\n",
    "        &= \\frac{1}{2}a_n\\left(3-a_n^2 r_{ij}^2\\right).\n",
    "\\end{align}\n",
    "\n",
    "In the original work of Jones et al. it was suggested that 5 or more iterations was sufficient to obtain acceptable accuracy. However, one needs a good initial guess for this to be the case, and as the Newton Raphson step is by far the most costly part of the quantum algorithm, it would be nice to reduce this prefactor.\n",
    "\n",
    "In the fusion paper this method is improved upon by using a hybrid approach based upon using QROM to load a good approximation to our function followed by a single step of Newton-Raphson. A further optimization is introduced to include the scaling factors necessary for the potential directly in the Newton-Raphson step (i.e. all the timestep and factors of two.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function interpolation\n",
    "\n",
    "The basic idea is to first fit a polynomial to $\\frac{1}{r_{ij}}$ to use as input for a Newton-Raphson step. In practice we do not want to try to fit $r_{ij}^{-1}$ over the entire range of values as this will lead to a poor quality fit. Instead we combine two ideas: piecewise interpolation and scaling. Piecewise interpolation allows us to boost the accuracy of our fit by splitting our domain into $k$ subintervals and fitting a polynomial in these smaller subintervals, which can then be pieced together on fly depending on the input value $\\bar{x}$. The second idea is to use the scaling properties of our function to only fit in a small subinterval, and appropriately scaling it if we need to know its value outside of this interval. That is, we know that $\\frac{1}{\\sqrt{x}} = \\frac{1}{\\sqrt{a}\\sqrt{x'}}$ for $x' \\in [1, 2]$, say.\n",
    "\n",
    "In practice we split the interval $[1, 2]$ in half, and fit the polynomial \n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt{x}} \\approx a_0 - a_1 (x-1) + a_2 (x-1)^2 - a_3 (x-1)^3\n",
    "$$\n",
    "\n",
    "for $x \\in [1, 3/2]$ and\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\sqrt{x}} \\approx b_0 - b_1 (x-3/2) + b_2 (x-3/2)^2 - b_3 (x-3/2)^3\n",
    "$$\n",
    "\n",
    "for $x \\in [3/2, 2]$.\n",
    "\n",
    "First let's see how these polynomials compare within their domains of definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qualtran.bloqs.chemistry.trotter.grid_ham.inverse_sqrt import get_inverse_square_root_poly_coeffs\n",
    "coeffs_one, coeffs_two = get_inverse_square_root_poly_coeffs()\n",
    "a0, a1, a2, a3 = coeffs_one\n",
    "b0, b1, b2, b3 = coeffs_two\n",
    "\n",
    "def polynomial_approx_range_one(x: float):\n",
    "    return a0 - (x-1) * (a1 - (x-1) * (a2 - a3*(x-1)))\n",
    "\n",
    "def polynomial_approx_range_two(x: float):\n",
    "    return b0 - (x-1.5) * (b1 - (x-1.5) * (b2 - b3*(x-1.5)))\n",
    "\n",
    "xs_one = np.linspace(1.0, 1.5, 10)\n",
    "poly_fit_one = polynomial_approx_range_one(xs_one)\n",
    "xs_two = np.linspace(1.5, 2.0, 10)\n",
    "poly_fit_two = polynomial_approx_range_two(xs_two)\n",
    "plt.plot(xs_one, np.abs(1.0 / xs_one**0.5 - poly_fit_one), marker='o', lw=0, label=\"range 1\")\n",
    "plt.plot(xs_two, np.abs(1.0 / xs_two**0.5 - poly_fit_two), marker='x', lw=0, label=\"range 2\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim([1e-6, 1e-4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that's pretty good. How does this compare after our step of Newton Raphson?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson_step(x, y0, delta=0.0):\n",
    "    # This odd delta shift let's us reduce the error by about a factor of two.\n",
    "    # Try commenting it out and see what the max error is after this step.\n",
    "    yprime = 0.5 * y0 * (3 + delta - y0**2 * x) \n",
    "    return yprime\n",
    "delta_range_one = 5.1642030908180720584e-9\n",
    "delta_range_two = 3.6279794522852781448e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_one = newton_raphson_step(xs_one, poly_fit_one, delta=delta_range_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_two = newton_raphson_step(xs_two, poly_fit_two, delta=delta_range_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xs_one, np.abs(1.0 / xs_one**0.5 - nr_one), marker='o', lw=0, label=\"range 1\")\n",
    "plt.plot(xs_two, np.abs(1.0 / xs_two**0.5 - nr_two), marker='x', lw=0, label=\"range 2\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim([1e-12, 1e-8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok great! We have a very accurate approximation to our function using if we can load some polynomial coefficients and perform some arithmetic. Next we will describe how we can use variable spaced QROM to efficiently load only a small amount of data to enable this procedure. \n",
    "\n",
    "## Variable Spaced QROM and Fitting the Entire Domain\n",
    "\n",
    "In this section we will discuss how we can use QROM along with function interpolation to approximate our function over the entire domain to high precision. But first let us convince ourselves that our two subintervals are sufficient and we can indeed fit our function by appropriately scaling our polynomial. For reasons that will become clear later, let us first group our allowed values of $r_{ij}^2$ in a logarithmic fashion as $0, 1, 2, 3, [4, 5], [6, 7], [8, 11], [12, 15], [16, 23], [24, 31], ...$ and so on. We can associate each of these integer intervals with our polynomial domains by noting that $[4, 5] = 2^2[1, 3/2]$, $[12, 15] = 2^3[3/2, 2]$, etc. Thus, we can evaluate our function for any value $r_{ij}^2$ after determining which \"bin\" it belongs to, determining the appropriate power of two, and scaling our polynomial appropriately. Let's test this below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from numpy.typing import NDArray\n",
    "# Recall we are using x in place of rij^2 here.\n",
    "def polynomial_approx_range_one_scaling(x: Union[float, NDArray[float]], scale_power: int):\n",
    "    r\"\"\"Evaluate the polynomial approximation to 1/\\sqrt{x}.\n",
    "\n",
    "    Args:\n",
    "        x: Where to evaluate the polynomial. This is rij^2. \n",
    "        scale_power: The power of two required to scale x back into the interval [1, 3/2].\n",
    "    \n",
    "    Returns:\n",
    "        y: The polynomial approximation to 1/\\sqrt{x} (i.e. 1/r_{ij}) in the first interval [1, 3/2].\n",
    "    \"\"\"\n",
    "    a0_scl = a0 / 2**(scale_power/2.0)\n",
    "    a1_scl = a1 / 2**(3*scale_power/2.0)\n",
    "    a2_scl = a2 / 2**(5*scale_power/2.0)\n",
    "    a3_scl = a3 / 2**(7*scale_power/2.0)\n",
    "    return a0_scl - (x-2**scale_power) * (a1_scl - (x-2**scale_power) * (a2_scl - a3_scl*(x-2**scale_power)))\n",
    "\n",
    "def polynomial_approx_range_two_scaling(x: float, scale_power: int=0):\n",
    "    r\"\"\"Evaluate the polynomial approximation to 1/\\sqrt{x}.\n",
    "\n",
    "    Args:\n",
    "        x: Where to evaluate the polynomial. This is rij^2. \n",
    "        scale_power: The power of two required to scale x back into the interval [3/2, 2].\n",
    "    \n",
    "    Returns:\n",
    "        y: The polynomial approximation to 1/\\sqrt{x} (i.e. 1/r_{ij}) in the first interval [3/2, 2].\n",
    "    \"\"\"\n",
    "    b0_scl = b0 / 2**(scale_power/2.0)\n",
    "    b1_scl = b1 / 2**(3*scale_power/2.0)\n",
    "    b2_scl = b2 / 2**(5*scale_power/2.0)\n",
    "    b3_scl = b3 / 2**(7*scale_power/2.0)\n",
    "    return b0_scl - (x-1.5*2**scale_power) * (b1_scl - (x-1.5*2**scale_power) * (b2_scl - b3_scl*(x-1.5*2**scale_power)))\n",
    "\n",
    "# Number of bits to represent the grid\n",
    "nbits = (2*ng + 1).bit_length()\n",
    "# Number of bits for r^2\n",
    "nbits_rsq = 2*nbits + 2\n",
    "# Here we determine the appropriate bins into which we subdivide our r_{ij}^2 values.\n",
    "bins_one = {0: [1], 1: [2]} \n",
    "bins_two = {1: [3]}\n",
    "rsq = 2**2\n",
    "while rsq < 2**nbits_rsq:\n",
    "    bl = int(rsq).bit_length() - 1\n",
    "    bins_one[bl] = [k for k in range(rsq, rsq+2**(bl-1))]\n",
    "    rsq += 2**(bl-1)\n",
    "    bins_two[bl] = [k for k in range(rsq, rsq+2**(bl-1))]\n",
    "    rsq += 2**(bl-1)\n",
    "\n",
    "# Fit the polynomial over the whole range.\n",
    "poly_one = []\n",
    "poly_two = []\n",
    "rsq_one = []\n",
    "rsq_two = []\n",
    "# check for our actual allowed values of r^2 for the grid\n",
    "for rsq in rij_int**2:\n",
    "    bl = int(rsq).bit_length() - 1\n",
    "    if rsq in bins_one[bl]:\n",
    "        poly_one.append(polynomial_approx_range_one_scaling(rsq, scale_power=bl))\n",
    "        rsq_one.append(rsq)\n",
    "    elif rsq in bins_two[bl]:\n",
    "        poly_two.append(polynomial_approx_range_two_scaling(rsq, scale_power=bl))\n",
    "        rsq_two.append(rsq)\n",
    "    else:\n",
    "        raise ValueError(\"Could not find bin for rsq.\")\n",
    "\n",
    "plt.plot(rsq_one, poly_one, marker='o', lw=0, label='range one')\n",
    "plt.plot(rsq_two, poly_two, marker='x', lw=0, label='range two')\n",
    "plt.plot(rij_int**2, 1/rij_int, label='Expected')\n",
    "plt.legend()\n",
    "plt.xlabel(\"$r_{ij}^2$\")\n",
    "plt.ylabel(r\"$\\frac{1}{\\sqrt{r_{ij}^2}}$\")\n",
    "# Check the global error\n",
    "combined_r = np.concatenate([rsq_one, rsq_two])\n",
    "ix = np.argsort(combined_r)\n",
    "combined = np.concatenate([poly_one, poly_two])[ix]\n",
    "nr_one = newton_raphson_step(np.array(rsq_one), np.array(poly_one), delta_range_one)\n",
    "nr_two = newton_raphson_step(np.array(rsq_two), np.array(poly_two), delta_range_two)\n",
    "combined_nr = np.concatenate([nr_one, nr_two])[ix]\n",
    "print(f\"max error = {np.max(np.abs(combined - 1/rij_int))} vs expected error = {2**(-15)}\")\n",
    "print(f\"max error after NR step = {np.max(np.abs(combined_nr - 1/rij_int))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! You might be wondering what is special about the intervals we chose to bin our integer $r_{ij}^2$ values by, and how QROM is connected with this. We'll try to explain that now.\n",
    "\n",
    "### QROM\n",
    "Recall that ultimately we need to load our polynomial coefficients onto the quantum computer before we can evaluate the inverse square root. Data loading can be achieved through QROM which implements: \n",
    "\n",
    "$$\n",
    "\\mathrm{QROM}_d \\sum_l \\alpha_l |l\\rangle|0\\rangle = \\sum_l \\alpha_l |l\\rangle|d_l\\rangle.\n",
    "$$\n",
    "\n",
    "That is, given a selection register $l$, QROM can load the binary representation of the $l$-th data element of $d$ into a target register of a given size.\n",
    "In our case $|r_{ij}^2\\rangle$ is the selection register of size $2 n + 2$, and we want to load $b$-bit binary representations of our polynomial coefficients $\\{a_0, a_1, a_2, a_3\\}$ and $\\{b_0, b_1, b_2, b_3\\}$ for the two ranges.\n",
    "\n",
    "In principle we could load all of the (scaled) coefficients for each value of $r_{ij}$ in the register, but this would incur a cost that goes like $L-1$ Toffolis, where $L=2^{2n + 2}$ which would be unacceptably large. But we just saw that much of this data would be duplicated as we only need the coefficients for each subinterval, of which there are a logarithmic amount. Fortunately we can exploit the structure of the unary iteration circuit to exploit this redundancy and significantly reduce our costs and arrive at variably space QROM.\n",
    "\n",
    "To understand where the reduction in cost comes from, consider the unary iteration circuit which is used during QROM construction. There, depending on the particular binary representation of the selection register, different parts of the tree are traversed before writing the data to a register. As we only care about certain subintervals (which were conveniently chosen as powers of two), we can delete parts of our unary iteration circuit where we want to repeat the data for that range of integers. The number of allowed integers in each range is determined in the following way: for the starting integer of the range $l$: if $k$ is the most significant bit of $l$, then the number of integers in our range is $2^{k-2}$ (we only bin integers when $k \\ge 2$). This is identical to how we set up our binning procedure earlier. Below is some code to generate the ranges given the values of the most significant bits of the selection register. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbits = 6\n",
    "nbits_rij_sq = 2 * nbits + 2\n",
    "print(f\"L = {2**nbits_rij_sq}\")\n",
    "hit = True \n",
    "g = 0\n",
    "for l in range(0, 2**nbits_rij_sq):\n",
    "    k = l.bit_length()\n",
    "    if k > 2:\n",
    "        if l & (1 << (k-2)) and not hit:\n",
    "            hit = True\n",
    "            print(f\"l = {l:0{nbits_rij_sq}b}, range = [{l:5d}, {l+2**(k-2)-1:5d}], length = {2**(k-2):>4d} {k}\")\n",
    "            g += 1\n",
    "        if not l & (1 << (k - 2)) and hit:\n",
    "            hit = False\n",
    "            print(f\"l = {l:0{nbits_rij_sq}b}, range = [{l:5d}, {l+2**(k-2)-1:5d}], length = {2**(k-2):>4d} {k}\")\n",
    "            g += 1\n",
    "# Add four to account for 0, 1, 2, 3\n",
    "print(f\"number of distinct regions g = {g + 4}. Toffoli cost g - 2 = {g - 2 + 4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see by the bit pattern that we can use the $k-1$ st bit to toggle between our two ranges [1, 3/2] and [3/2, 2]. The total Toffoli cost is then just g - 2, which is 26 if $r_{ij}^2$ is stored with 14 bits. Note we can store the coefficients to high precision as there is only a small clifford overhead associated with this. In the fusion paper 15 bits of precision is suggested as sufficient. \n",
    "\n",
    "To summarize we:\n",
    "\n",
    "1. Fit our function $1/x$ in two intervals [1, 3/2] and [3/2, 2].\n",
    "2. Given a value of $r_{ij}$, use variably spaced qrom to output the appropriately scaled polynomial coefficients.\n",
    "3. Evaluate the polynomial.\n",
    "4. Perform a single step of Newton Raphson.\n",
    "5. Apply a phase to our wavefunction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trotter Unitaries\n",
    "\n",
    "Ok, now that we have the setup straight in our heads lets build our bloqs and perform resource estimations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kinetic Energy Bloq\n",
    "Recall that the kinetic energy is diagonal in the momentum basis, which we are assuming our state is in following a ```QFT```. The basic algorithm is then\n",
    "\n",
    "1. For each electron $i$ compute $|\\mathbf{k}^2 \\rangle = |k_x^2 + k_y^2 + k_j^2\\rangle$ of size $2n + 2$.\n",
    "2. Apply $e^{-i\\frac{\\delta t}{2} \\sum_i k^2_i }|\\psi\\rangle = \\prod_i e^{-i\\frac{\\delta t}{2} k_i^2}|\\psi\\rangle$, where the equality holds as each term in the sum commutes.\n",
    "\n",
    "Our bloq implementing this is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qualtran.bloqs.chemistry.trotter.grid_ham import KineticEnergy \n",
    "from qualtran.drawing import show_bloq\n",
    "num_elec = 2\n",
    "num_grid_each_dim = 2*10 + 1\n",
    "ke_bloq = KineticEnergy(num_elec, num_grid_each_dim)\n",
    "show_bloq(ke_bloq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ke_bloq.t_complexity())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Energy Bloq\n",
    "\n",
    "Here we consider the electron-electron interaction\n",
    "\\begin{align}\n",
    "V &= \\sum_{i < j} \\frac{1}{|r_i-r_j|} \\\\\n",
    "  &= \\sum_{i < j} V_{ij}\n",
    "\\end{align}\n",
    "Again, as the individual terms commute (diagonal in our real space grid basis), we can decompose our unitary into a product of $\\eta (\\eta - 1)$ unitaries implementing all of the $V_{ij}$ pair potentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qualtran.bloqs.chemistry.trotter.grid_ham import PotentialEnergy\n",
    "from qualtran.drawing import show_bloq, show_call_graph\n",
    "num_elec = 2\n",
    "num_grid_each_dim = 2*10 + 1\n",
    "coeffs_a = []\n",
    "pe_bloq = PotentialEnergy(num_elec, num_grid_each_dim)\n",
    "show_bloq(pe_bloq.decompose_bloq())\n",
    "print(pe_bloq.t_complexity())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our $V_{ij}$ bloq then implements the steps discussed previously, let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qualtran.bloqs.chemistry.trotter.grid_ham import PairPotential\n",
    "from qualtran.bloqs.chemistry.trotter.grid_ham.inverse_sqrt import build_qrom_data_for_poly_fit\n",
    "poly_coeffs = get_inverse_square_root_poly_coeffs()\n",
    "num_elec = 2\n",
    "num_grid_each_dim = 2*10 + 1\n",
    "nbits = 6\n",
    "qrom_data = build_qrom_data_for_poly_fit(2*nbits+2, 15, poly_coeffs)\n",
    "qrom_data = tuple(tuple(int(k) for k in d) for d in qrom_data)\n",
    "pp_bloq = PairPotential(nbits, qrom_data, poly_bitsize=15)\n",
    "print(pp_bloq.t_complexity())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to Costs in Paper\n",
    "\n",
    "We're now in a position to compare our qualtran costs to those in the paper, which were rough estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attrs\n",
    "import cirq\n",
    "\n",
    "from qualtran.resource_counting import SympySymbolAllocator\n",
    "from qualtran.drawing import GraphvizCounts\n",
    "from qualtran.bloqs.util_bloqs import Split, Join, Allocate, Free\n",
    "from qualtran.bloqs.basic_gates.rotation import Rx, Ry, Rz\n",
    "from qualtran.cirq_interop import CirqGateAsBloq\n",
    "from qualtran.bloqs.mcmt import And\n",
    "\n",
    "# Ignore some parts of the decomposition which aren't helpful for visualization.\n",
    "ssa = SympySymbolAllocator()\n",
    "phi = ssa.new_symbol('phi')\n",
    "and_cv0 = ssa.new_symbol('cv0')\n",
    "and_cv1 = ssa.new_symbol('cv1')\n",
    "\n",
    "def custom_repr(self):\n",
    "    selection_repr = repr(self.selection_bitsizes)\n",
    "    target_repr = repr(self.target_bitsizes)\n",
    "    return (f\"QROM(selection_bitsizes={selection_repr}, \"\n",
    "        f\"target_bitsizes={target_repr}, num_controls={self.num_controls})\"\n",
    "    )\n",
    "\n",
    "cirq_cliffords_ignore = (\n",
    "    cirq.ops.common_gates.HPowGate,\n",
    "    cirq.ops.common_gates.XPowGate,\n",
    "    cirq.ops.common_gates.YPowGate,\n",
    "    cirq.ops.common_gates.ZPowGate,\n",
    "    cirq.ops.common_gates.CXPowGate,\n",
    ")\n",
    "def generalize(bloq):\n",
    "    if isinstance(bloq, CirqGateAsBloq):\n",
    "        if isinstance(bloq.gate, And) and (len(bloq.gate.cv) == 2):\n",
    "            return And(cv1=and_cv0, cv2=and_cv1, adjoint=bloq.gate.adjoint)\n",
    "        if isinstance(bloq.gate, cirq_cliffords_ignore):\n",
    "            return None\n",
    "    if isinstance(bloq, (Join, Split, Allocate, Free)):\n",
    "        return None\n",
    "    if isinstance(bloq, (Rx, Ry, Rz)):\n",
    "        return attrs.evolve(bloq, angle=phi)\n",
    "    return bloq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qualtran.bloqs.chemistry.trotter.grid_ham.inverse_sqrt import PolynmomialEvaluationInverseSquareRoot \n",
    "poly_eval = PolynmomialEvaluationInverseSquareRoot(14, 15, 24)\n",
    "graph, sigma = poly_eval.call_graph(generalizer=generalize)\n",
    "show_call_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_cost = 4 * (3*15**2 + 45)\n",
    "print(f\"qualtran cost = {poly_eval.t_complexity().t} vs paper_cost = {paper_cost} T gates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qualtran.bloqs.chemistry.trotter.grid_ham.inverse_sqrt import NewtonRaphsonApproxInverseSquareRoot\n",
    "nr = NewtonRaphsonApproxInverseSquareRoot(14, 15, 24)\n",
    "graph, sigma = nr.call_graph(generalizer=generalize)\n",
    "show_call_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_cost = 4 * (2136 - 3*15**2 - 45)\n",
    "print(f\"qualtran cost = {nr.t_complexity().t} vs paper cost = {paper_cost} T gates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qualtran.bloqs.chemistry.trotter.grid_ham import KineticEnergy \n",
    "ke = KineticEnergy(4, 21)\n",
    "graph, sigma = ke.call_graph(generalizer=generalize)\n",
    "show_call_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qualtran.bloqs.chemistry.trotter.grid_ham import PotentialEnergy \n",
    "pe = PotentialEnergy(4, 21)\n",
    "graph, sigma = pe.call_graph(generalizer=generalize)\n",
    "show_call_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the costs of doing just the pair potential. Note that the Fusion paper does not count the cost of applying the phase and also our qualtran estimates does not account for the bit shifting necessary to deal with small values of $x$. The bit shifting cost is about $n(n+1) + 15n$, which we do not include in the comparison below. The cost of uncomputing the arithmetic is also ignored in both estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qualtran.bloqs.chemistry.trotter.grid_ham import PairPotential\n",
    "nbits = 6\n",
    "poly_coeffs = get_inverse_square_root_poly_coeffs()\n",
    "qrom_data = build_qrom_data_for_poly_fit(2*nbits+2, 15, poly_coeffs)\n",
    "qrom_data = tuple(tuple(int(k) for k in d) for d in qrom_data)\n",
    "\n",
    "pe = PairPotential(6, qrom_data)\n",
    "graph, sigma = pe.call_graph(generalizer=generalize)\n",
    "paper_cost = (\n",
    "    2136 # poly interp + newton raphson\n",
    "    + (3*nbits**2 - nbits - 1) # sum of squares\n",
    "    + (4*nbits + 2) # QROM\n",
    ")\n",
    "print(f\"qualtran_cost = {pe.t_complexity().t-24*52} vs paper_cost = {4*paper_cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "Note in practice we really use fixed point representation of floating numbers.\n",
    "\n",
    "### Fixed point and binary arithmetic\n",
    "\n",
    "To evaluate the polynomial and Newton-Raphson step we need fixed-point arithmetic (addition, multiplication, squaring and scaling). Recall that fixed-point real valued (between 0 and 1) numbers are approximated as (using a convention where the most significant bit is yielded first)\n",
    "\n",
    "$$\n",
    "\\kappa = \\sum_{l=0}^{b_r-1} \\kappa_l/2^{l+1}, \\ \\ \\ \\ \\kappa_l \\in \\{0, 1\\}\n",
    "$$\n",
    "\n",
    "while (positive) integers can be represented as\n",
    "\n",
    "$$\n",
    "\\lambda = \\sum_{l=0}^{b_i-1} 2^{b_i - l} \\lambda_l, \\ \\ \\ \\ \\lambda_l \\in \\{0, 1\\}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
