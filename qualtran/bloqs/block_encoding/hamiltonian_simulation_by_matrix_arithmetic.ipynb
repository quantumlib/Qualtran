{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamiltonian Simulation by Matrix Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how we can use Qualtran's block encoding library to encode and transform data as part of a complex quantum algorithm. \n",
    "\n",
    "Specifically, we will study [A quantum algorithm for the linear Vlasov equation with collions](https://arxiv.org/abs/2303.03450) by Ameri et al. (2023), which simulates the dynamics of plasmas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on Speedup\n",
    "\n",
    "As stated by the authors, this \"quantum algorithm ... can yield a quadratic speedup compared to classical algorithms that solve the same system of equations. An exponential speedup, however, does not seem possible with currently known methods due to the large norm of the matrices involved.\"\n",
    "\n",
    "As such, one goal of this notebook will be to perform a concrete resource estimate of the quantum algorithm to help us ascertain its speedup in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import jv\n",
    "\n",
    "from qualtran.bloqs.basic_gates import Identity\n",
    "from qualtran.bloqs.block_encoding import (\n",
    "    BlockEncoding,\n",
    "    ScaledChebyshevPolynomial,\n",
    "    LinearCombination,\n",
    "    Phase,\n",
    "    Product,\n",
    "    TensorProduct,\n",
    "    Unitary,\n",
    ")\n",
    "from qualtran.bloqs.block_encoding.sparse_matrix import (\n",
    "    SymmetricBandedRowColumnOracle,\n",
    "    ExplicitEntryOracle,\n",
    "    SparseMatrix,\n",
    ")\n",
    "from qualtran.bloqs.block_encoding.rewrites import collect_like_terms\n",
    "from qualtran.bloqs.block_encoding.vlasov_equation import VlasovEntryOracle\n",
    "from qualtran.resource_counting.generalizers import ignore_split_join\n",
    "from qualtran.resource_counting.t_counts_from_sigma import t_counts_from_sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Formulation\n",
    "\n",
    "The algorithm solves the collisional Vlasov-Poisson equation (Eq. 1 and 2 in the reference). We focus on the core of the algorithm, which solves the following ODE:\n",
    "\n",
    "$$ \\frac{d\\mathbf{g}_k}{dt} = A\\mathbf{g}_k $$\n",
    "\n",
    "with solution\n",
    "\n",
    "$$ \\mathbf{g}_k(t) = e^{At} \\mathbf{g}_k(t = 0) $$\n",
    "\n",
    "where $\\mathbf{g}_k(0)$ is the initial condition and $A$ is a 3-sparse matrix:\n",
    "\n",
    "$$ A = -ikH + \\nu\\ \\mathrm{diag}([0, 0, 2, \\ldots, M - 1, M]) $$\n",
    "\n",
    "with\n",
    "\n",
    "$$ H = \\begin{bmatrix}\n",
    "0 & \\sqrt{\\frac{1 + \\alpha}{2}} \\\\\n",
    "\\sqrt{\\frac{1 + \\alpha}{2}} & 0 & 1 \\\\\n",
    " & 1 & 0 & \\sqrt{\\frac{3}{2}} \\\\\n",
    " &   & \\ddots & \\ddots & \\ddots \\\\\n",
    "& & & \\sqrt{\\frac{M - 1}{2}} & 0 & \\sqrt{\\frac{M}{2}} \\\\\n",
    "& & & & \\sqrt{\\frac{M}{2}} & 0\n",
    "\\end{bmatrix} $$\n",
    "\n",
    "where $k, \\nu, \\alpha$ are parameters of the physical system and $n$ is the number of qubits in the system, with the system size $M = 2^n - 1$.\n",
    "\n",
    "For simplicity, we focus on the case where $\\nu = 0, k = 1$, in which case the solution is:\n",
    "\n",
    "$$ \\mathbf{g}_k(t) = e^{-iHt} \\mathbf{g}_k(t = 0) $$\n",
    "\n",
    "which takes the familiar form of Hamiltonian simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "In principle, there are numerous methods to realize the unitary operator $e^{-iHt}$ in this problem. Our approach will be to decompose $e^{-iHt} = \\cos(Ht) + i\\sin(Ht)$, and then use the Jacobi-Anger decomposition:\n",
    "\n",
    "$$\\cos(Xt) = J_0(t) + 2 \\sum_{k=1}^\\infty (-1)^k J_{2k}(t)T_{2k}(X)$$\n",
    "\n",
    "$$\\sin(Xt) = 2 \\sum_{k=0}^\\infty (-1)^k J_{2k+1}(t)T_{2k+1}(X)$$\n",
    "\n",
    "where $J_n$ denotes the $n$-th Bessel function of the first kind and $T_n$ denotes the $n$-th Chebyshev polynomial of the first kind.\n",
    "\n",
    "Using Qualtran's block encoding library, we will produce a block encoding of $H$ as given by the matrix above, and complete each of the above decomposition steps via matrix arithmetic on block encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use $T$-complexity as the cost metric. However, following [Sunderhauf et al.](https://arxiv.org/abs/2302.10949), we will multiply the $T$-complexity of each block encoding $\\mathcal{B}[A/\\alpha]$ by its normalization factor $\\alpha$. This because $\\alpha$ is proportional to the number of repetitions we expect to need to successfully post-select $A$ when given the block encoding $\\mathcal{B}[A/\\alpha]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_count(bloq: BlockEncoding):\n",
    "    _, sigma = bloq.call_graph(generalizer=ignore_split_join)\n",
    "    return int(t_counts_from_sigma(sigma) * bloq.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Powers\n",
    "\n",
    "Given a block encoding $\\mathcal{B}[X]$ of a matrix $X$, Qualtran makes it simple to compute a block encoding of its powers $\\mathcal{B}[X^n]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity(x: BlockEncoding) -> BlockEncoding:\n",
    "    '''Given B[A], return B[A^0]'''\n",
    "    return TensorProduct(tuple(Unitary(Identity()) for _ in range(x.system_bitsize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def power(n: int, x: BlockEncoding) -> BlockEncoding:\n",
    "    '''Given B[A], return B[A^n].'''\n",
    "    if n == 0:\n",
    "        return identity(x)\n",
    "    return Product.of(x, power(n - 1, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chebyshev Polynomials\n",
    "\n",
    "We can next define a block encoding of the Chebyshev polynomial $\\mathcal{B}[T_n(X)]$ of a matrix. The definition of $T_n(x)$ is:\n",
    "\n",
    "$$ T_0(x) = 1 $$\n",
    "$$ T_1(x) = x $$\n",
    "$$ T_{n+1}(x) = 2x T_n(x) - T_{n-1}(x) $$\n",
    "\n",
    "We can translate this textbook recursive definition into code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.cache\n",
    "def chebyshev_exp(n: int, x: BlockEncoding) -> BlockEncoding:\n",
    "    '''Implementation of B[T_n(x)] that scales as O(2^n).'''\n",
    "    if n == 0:\n",
    "        return identity(x)\n",
    "    if n == 1:\n",
    "        return x\n",
    "    return LinearCombination.of_terms(\n",
    "        (2.0, Product.of(x, chebyshev_exp(n - 1, x))), (-1.0, chebyshev_exp(n - 2, x))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though simple and correct, the above implementation has a gate complexity that scales as $O(2^n)$ due to the two recursive calls. We can optimize it to $O(n^2)$ by precomputing the Chebyshev coefficients and multiplying each by the appropriate power of the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebyshev_quad(n: int, x: BlockEncoding) -> BlockEncoding:\n",
    "    '''Implementation of B[T_n(x)] that scales as O(n^2).'''\n",
    "    if n == 0:\n",
    "        return identity(x)\n",
    "    if n == 1:\n",
    "        return x\n",
    "    coeffs = np.polynomial.chebyshev.cheb2poly([0] * n + [1])\n",
    "    terms = ((coeff, power(i, x)) for i, coeff in enumerate(coeffs) if coeff != 0)\n",
    "    return LinearCombination.of_terms(*terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, we could further improve the complexity to $O(n)$ with the qubitization technique of [Low and Chuang (2018)](https://arxiv.org/abs/1610.06546). This technique is implemented by Qualtran's `ChebyshevPolynomial` bloq.\n",
    "\n",
    "There is a technical wrinkle, however: the qubitization technique only works correctly when given a block encoding with $\\alpha = 1$, which will not be the case here. \n",
    "\n",
    "Our solution is to use Qualtran's `ScaledChebyshevPolynomial` bloq, which assembles a linear combination of Chebyshev polynomials that works correctly with $\\alpha \\neq 1$. By itself, this step increases the complexity back to $O(n^2)$. However, we will use Qualtran's `collect_like_terms` optimizer to fuse this linear combination with other terms in the decomposition of sine and cosine, essentially amortizing out this cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chebyshev_fast(n: int, x: BlockEncoding) -> BlockEncoding:\n",
    "    '''Implementation of B[T_n(x)] that scales as O(n).'''\n",
    "\n",
    "    return ScaledChebyshevPolynomial(x, n).linear_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshev = chebyshev_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jacobi-Anger Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then construct the Jacobi-Anger approximation of sine and cosine:\n",
    "\n",
    "$$\\cos(Xt) = J_0(t) + 2 \\sum_{k=1}^\\infty (-1)^k J_{2k}(t)T_{2k}(X)$$\n",
    "\n",
    "$$\\sin(Xt) = 2 \\sum_{k=0}^\\infty (-1)^k J_{2k+1}(t)T_{2k+1}(X)$$\n",
    "\n",
    "where we truncate $\\infty$ to some $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_anger_cosine(t: float, h: BlockEncoding, K: int) -> BlockEncoding:\n",
    "    return LinearCombination(\n",
    "        (identity(h),) + tuple(chebyshev(2 * k, h) for k in range(1, K)),\n",
    "        (jv(0, t),) + tuple(2 * (-1) ** k * jv(2 * k, t) for k in range(1, K)),\n",
    "        lambd_bits=9,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacobi_anger_sine(t: float, h: BlockEncoding, K: int) -> BlockEncoding:\n",
    "    return LinearCombination(\n",
    "        tuple(chebyshev(2 * k + 1, h) for k in range(K)),\n",
    "        tuple(2 * (-1) ** k * jv(2 * k + 1, t) for k in range(K)),\n",
    "        lambd_bits=9,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Block Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define the physical parameters of the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenumber = 2\n",
    "alpha = 2 / wavenumber**2\n",
    "t = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to construct a block-encoding of $H$. \n",
    "\n",
    "We use an oracle to perform arithmetic (subtraction, division, square root) to compute each element $H_{ij}$ of the matrix given its index $(i, j)$. This oracle is implemented by the `VlasovEntryOracle` bloq in Qualtran.\n",
    "\n",
    "We also use an oracle to specify the positions of the 3 nonzero elements in each row/column $i$, which are $i-1$, $i$, and $i+1$. This oracle is implemented by `SymmetricBandedRowColumnOracle` in Qualtran. Putting it all together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vlasov_bloq(n, K, entry_oracle):\n",
    "    row_oracle = SymmetricBandedRowColumnOracle(n, bandsize=1)\n",
    "    col_oracle = SymmetricBandedRowColumnOracle(n, bandsize=1)\n",
    "    h = SparseMatrix(row_oracle, col_oracle, entry_oracle, eps=0)\n",
    "    cos = jacobi_anger_cosine(t * h.alpha, h, K)\n",
    "    isin = Phase(jacobi_anger_sine(t * h.alpha, h, K), phi=np.pi, eps=1e-11)\n",
    "    return collect_like_terms(LinearCombination.of_terms((1.0, cos), (1.0, isin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vlasov_sparse(n, K):\n",
    "    return vlasov_bloq(n, K, VlasovEntryOracle(system_bitsize=n, entry_bitsize=n + 3, alpha=alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we can also implement an alternative block encoding of $H$ from a classically pre-computed matrix, which we load via QROM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vlasov_hamiltonian(n: int, alpha: float):\n",
    "    data = np.zeros((2**n, 2**n))\n",
    "    data[0][1] = data[1][0] = np.sqrt((1 + alpha) / 2)\n",
    "    for i in range(2, 2**n):\n",
    "        data[i - 1][i] = data[i][i - 1] = np.sqrt(i / 2)\n",
    "    data /= np.max(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vlasov_explicit(n, K):\n",
    "    data = gen_vlasov_hamiltonian(n, alpha)\n",
    "    return vlasov_bloq(n, K, ExplicitEntryOracle(system_bitsize=n, data=data, entry_bitsize=n + 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Comparison\n",
    "\n",
    "We can compare the cost of using QROM to load the explicit matrix for $H$ versus computing the block encoding using quantum arithmetic, in terms of the system size $n$ and the degree $K$ to which the Jacobi-Anger decomposition is truncated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshev = chebyshev_fast\n",
    "explicit_n = list(t_count(vlasov_explicit(n, 5)) for n in range(2, 7))\n",
    "sparse_n = list(t_count(vlasov_sparse(n, 5)) for n in range(2, 14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('Number of T gates')\n",
    "plt.ylim(0, 5e6)\n",
    "plt.xlabel('dimension n of Vlasov equation Hamiltonian')\n",
    "plt.plot(range(2, 7), explicit_n, marker='o', label='explicit matrix from QROM')\n",
    "plt.plot(range(2, 14), sparse_n, marker='o', label='sparse matrix from oracle')\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows that the complexity of the block encoding of $e^{-iHt}$ scales with $O(2^n)$ when using QROM and $O(n)$ with quantum arithmetic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the costs of the different ways of computing the Chebyshev polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chebyshev = chebyshev_fast\n",
    "sparse_k = list(t_count(vlasov_sparse(5, K)) for K in range(2, 14))\n",
    "\n",
    "chebyshev = chebyshev_exp\n",
    "sparse0_k = list(t_count(vlasov_sparse(5, K)) for K in range(2, 7))\n",
    "\n",
    "chebyshev = chebyshev_quad\n",
    "sparse1_k = list(t_count(vlasov_sparse(5, K)) for K in range(2, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel('Number of T gates')\n",
    "plt.ylim(0, 3e7)\n",
    "plt.xlabel('degree K of polynomial in Jacobi-Anger approximation')\n",
    "plt.plot(range(2, 7), sparse0_k, marker='o', label='chebyshev_exp')\n",
    "plt.plot(range(2, 10), sparse1_k, marker='o', label='chebyshev_quad')\n",
    "plt.plot(range(2, 14), sparse_k, marker='o', label='chebyshev_fast')\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirically, when using the efficient method to compute the Chebyshev polynomial, the overall complexity of the block encoding of $e^{-iHt}$ scales as $O(nK^2)$. The quadratic scaling in $K$ is due to the computation of the linear combination of $K$ Chebyshev polynomials, each of which has $O(K)$ amortized complexity, in the Jacobi-Anger decomposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qualtran",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
