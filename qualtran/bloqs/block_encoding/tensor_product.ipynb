{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c24893",
   "metadata": {
    "cq.autogen": "title_cell"
   },
   "source": [
    "# Tensor Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4600b",
   "metadata": {
    "cq.autogen": "top_imports"
   },
   "outputs": [],
   "source": [
    "from qualtran import Bloq, CompositeBloq, BloqBuilder, Signature, Register\n",
    "from qualtran import QBit, QInt, QUInt, QAny\n",
    "from qualtran.drawing import show_bloq, show_call_graph, show_counts_sigma\n",
    "from typing import *\n",
    "import numpy as np\n",
    "import sympy\n",
    "import cirq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4845e5b",
   "metadata": {
    "cq.autogen": "TensorProduct.bloq_doc.md"
   },
   "source": [
    "## `TensorProduct`\n",
    "Tensor product of a sequence of block encodings.\n",
    "\n",
    "Builds the block encoding as\n",
    "$$\n",
    "    B[U_1 ⊗ U_2 ⊗ \\cdots ⊗ U_n] = B[U_1] ⊗ B[U_2] ⊗ \\cdots ⊗ B[U_n]\n",
    "$$\n",
    "\n",
    "When each $B[U_i]$ is a $(\\alpha_i, a_i, \\epsilon_i)$-block encoding of $U_i$, we have that\n",
    "$B[U_1 ⊗ \\cdots ⊗ U_n]$ is a $(\\prod_i \\alpha_i, \\sum_i a_i, \\sum_i \\alpha_i \\epsilon_i)$-block\n",
    "encoding of $U_1 ⊗ \\cdots ⊗ U_n$.\n",
    "\n",
    "#### Parameters\n",
    " - `block_encodings`: A sequence of block encodings. \n",
    "\n",
    "#### Registers\n",
    " - `system`: The system register.\n",
    " - `ancilla`: The ancilla register (present only if bitsize > 0).\n",
    " - `resource`: The resource register (present only if bitsize > 0). \n",
    "\n",
    "#### References\n",
    " - [Quantum algorithms: A survey of applications and end-to-end complexities](https://arxiv.org/abs/2310.03011). Dalzell et al. (2023). Ch. 10.2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8707cfbc",
   "metadata": {
    "cq.autogen": "TensorProduct.bloq_doc.py"
   },
   "outputs": [],
   "source": [
    "from qualtran.bloqs.block_encoding import TensorProduct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28a1c5",
   "metadata": {
    "cq.autogen": "TensorProduct.example_instances.md"
   },
   "source": [
    "### Example Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e861ef9b",
   "metadata": {
    "cq.autogen": "TensorProduct.tensor_product_block_encoding"
   },
   "outputs": [],
   "source": [
    "from qualtran.bloqs.basic_gates import Hadamard, TGate\n",
    "from qualtran.bloqs.block_encoding.unitary import Unitary\n",
    "\n",
    "tensor_product_block_encoding = TensorProduct((Unitary(TGate()), Unitary(Hadamard())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a8613d",
   "metadata": {
    "cq.autogen": "TensorProduct.tensor_product_block_encoding_properties"
   },
   "outputs": [],
   "source": [
    "from attrs import evolve\n",
    "\n",
    "from qualtran.bloqs.basic_gates import CNOT, TGate\n",
    "from qualtran.bloqs.block_encoding.unitary import Unitary\n",
    "\n",
    "u1 = evolve(Unitary(TGate()), alpha=0.5, ancilla_bitsize=2, resource_bitsize=1, epsilon=0.01)\n",
    "u2 = evolve(Unitary(CNOT()), alpha=0.5, ancilla_bitsize=1, resource_bitsize=1, epsilon=0.1)\n",
    "tensor_product_block_encoding_properties = TensorProduct((u1, u2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89beb2a",
   "metadata": {
    "cq.autogen": "TensorProduct.tensor_product_block_encoding_symb"
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "\n",
    "from qualtran.bloqs.basic_gates import Hadamard, TGate\n",
    "from qualtran.bloqs.block_encoding.unitary import Unitary\n",
    "\n",
    "alpha1 = sympy.Symbol('alpha1')\n",
    "a1 = sympy.Symbol('a1')\n",
    "eps1 = sympy.Symbol('eps1')\n",
    "alpha2 = sympy.Symbol('alpha2')\n",
    "a2 = sympy.Symbol('a2')\n",
    "eps2 = sympy.Symbol('eps2')\n",
    "tensor_product_block_encoding_symb = TensorProduct(\n",
    "    (\n",
    "        Unitary(TGate(), alpha=alpha1, ancilla_bitsize=a1, epsilon=eps1),\n",
    "        Unitary(Hadamard(), alpha=alpha2, ancilla_bitsize=a2, epsilon=eps2),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2885ef",
   "metadata": {
    "cq.autogen": "TensorProduct.graphical_signature.md"
   },
   "source": [
    "#### Graphical Signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c951e2",
   "metadata": {
    "cq.autogen": "TensorProduct.graphical_signature.py"
   },
   "outputs": [],
   "source": [
    "from qualtran.drawing import show_bloqs\n",
    "show_bloqs([tensor_product_block_encoding, tensor_product_block_encoding_properties, tensor_product_block_encoding_symb],\n",
    "           ['`tensor_product_block_encoding`', '`tensor_product_block_encoding_properties`', '`tensor_product_block_encoding_symb`'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bc0175",
   "metadata": {
    "cq.autogen": "TensorProduct.call_graph.md"
   },
   "source": [
    "### Call Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c5e76",
   "metadata": {
    "cq.autogen": "TensorProduct.call_graph.py"
   },
   "outputs": [],
   "source": [
    "from qualtran.resource_counting.generalizers import ignore_split_join\n",
    "tensor_product_block_encoding_g, tensor_product_block_encoding_sigma = tensor_product_block_encoding.call_graph(max_depth=1, generalizer=ignore_split_join)\n",
    "show_call_graph(tensor_product_block_encoding_g)\n",
    "show_counts_sigma(tensor_product_block_encoding_sigma)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
